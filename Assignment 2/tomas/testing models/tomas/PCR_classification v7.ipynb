{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlrd in /opt/anaconda3/envs/MLE/lib/python3.10/site-packages (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pCR (outcome)</th>\n",
       "      <th>RelapseFreeSurvival (outcome)</th>\n",
       "      <th>Age</th>\n",
       "      <th>ER</th>\n",
       "      <th>PgR</th>\n",
       "      <th>HER2</th>\n",
       "      <th>TrippleNegative</th>\n",
       "      <th>ChemoGrade</th>\n",
       "      <th>Proliferation</th>\n",
       "      <th>HistologyType</th>\n",
       "      <th>...</th>\n",
       "      <th>original_glszm_SmallAreaHighGrayLevelEmphasis</th>\n",
       "      <th>original_glszm_SmallAreaLowGrayLevelEmphasis</th>\n",
       "      <th>original_glszm_ZoneEntropy</th>\n",
       "      <th>original_glszm_ZonePercentage</th>\n",
       "      <th>original_glszm_ZoneVariance</th>\n",
       "      <th>original_ngtdm_Busyness</th>\n",
       "      <th>original_ngtdm_Coarseness</th>\n",
       "      <th>original_ngtdm_Complexity</th>\n",
       "      <th>original_ngtdm_Contrast</th>\n",
       "      <th>original_ngtdm_Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>144.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517172</td>\n",
       "      <td>0.375126</td>\n",
       "      <td>3.325332</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>3880771.500</td>\n",
       "      <td>473.464852</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.182615</td>\n",
       "      <td>0.030508</td>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444391</td>\n",
       "      <td>0.444391</td>\n",
       "      <td>3.032144</td>\n",
       "      <td>0.005612</td>\n",
       "      <td>2372009.744</td>\n",
       "      <td>59.459710</td>\n",
       "      <td>0.004383</td>\n",
       "      <td>0.032012</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.003685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>135.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534549</td>\n",
       "      <td>0.534549</td>\n",
       "      <td>2.485848</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>1540027.421</td>\n",
       "      <td>33.935384</td>\n",
       "      <td>0.007584</td>\n",
       "      <td>0.024062</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.006447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506185</td>\n",
       "      <td>0.506185</td>\n",
       "      <td>2.606255</td>\n",
       "      <td>0.003755</td>\n",
       "      <td>6936740.794</td>\n",
       "      <td>46.859265</td>\n",
       "      <td>0.005424</td>\n",
       "      <td>0.013707</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.004543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.462282</td>\n",
       "      <td>0.462282</td>\n",
       "      <td>2.809279</td>\n",
       "      <td>0.006521</td>\n",
       "      <td>1265399.054</td>\n",
       "      <td>39.621023</td>\n",
       "      <td>0.006585</td>\n",
       "      <td>0.034148</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.005626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pCR (outcome)  RelapseFreeSurvival (outcome)   Age  ER  PgR  HER2  \\\n",
       "0              1                          144.0  41.0   0    0     0   \n",
       "1              0                          142.0  39.0   1    1     0   \n",
       "2              1                          135.0  31.0   0    0     0   \n",
       "3              0                           12.0  35.0   0    0     0   \n",
       "4              0                          109.0  61.0   1    0     0   \n",
       "\n",
       "   TrippleNegative  ChemoGrade  Proliferation  HistologyType  ...  \\\n",
       "0                1           3              3              1  ...   \n",
       "1                0           3              3              1  ...   \n",
       "2                1           2              1              1  ...   \n",
       "3                1           3              3              1  ...   \n",
       "4                0           2              1              1  ...   \n",
       "\n",
       "   original_glszm_SmallAreaHighGrayLevelEmphasis  \\\n",
       "0                                       0.517172   \n",
       "1                                       0.444391   \n",
       "2                                       0.534549   \n",
       "3                                       0.506185   \n",
       "4                                       0.462282   \n",
       "\n",
       "   original_glszm_SmallAreaLowGrayLevelEmphasis  original_glszm_ZoneEntropy  \\\n",
       "0                                      0.375126                    3.325332   \n",
       "1                                      0.444391                    3.032144   \n",
       "2                                      0.534549                    2.485848   \n",
       "3                                      0.506185                    2.606255   \n",
       "4                                      0.462282                    2.809279   \n",
       "\n",
       "   original_glszm_ZonePercentage  original_glszm_ZoneVariance  \\\n",
       "0                       0.002314                  3880771.500   \n",
       "1                       0.005612                  2372009.744   \n",
       "2                       0.006752                  1540027.421   \n",
       "3                       0.003755                  6936740.794   \n",
       "4                       0.006521                  1265399.054   \n",
       "\n",
       "   original_ngtdm_Busyness  original_ngtdm_Coarseness  \\\n",
       "0               473.464852                   0.000768   \n",
       "1                59.459710                   0.004383   \n",
       "2                33.935384                   0.007584   \n",
       "3                46.859265                   0.005424   \n",
       "4                39.621023                   0.006585   \n",
       "\n",
       "   original_ngtdm_Complexity  original_ngtdm_Contrast  original_ngtdm_Strength  \n",
       "0                   0.182615                 0.030508                 0.000758  \n",
       "1                   0.032012                 0.001006                 0.003685  \n",
       "2                   0.024062                 0.000529                 0.006447  \n",
       "3                   0.013707                 0.000178                 0.004543  \n",
       "4                   0.034148                 0.001083                 0.005626  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Install xlrd package\n",
    "%pip install xlrd\n",
    "\n",
    "all_df = pd.read_excel('TrainDataset2024.xls', index_col=False)\n",
    "all_df.drop('ID', axis=1, inplace=True)\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Replace missing values with median of the column\n",
    "imputer = SimpleImputer(strategy=\"median\", missing_values=999)\n",
    "all_df[:] = imputer.fit_transform(all_df)\n",
    "\n",
    "# classification target\n",
    "clf_y = all_df['pCR (outcome)']\n",
    "# regression target\n",
    "rgr_y = all_df['RelapseFreeSurvival (outcome)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier removal approach by:\n",
    "# Thanaki, Jalaj. Machine Learning Solutions : Expert Techniques to Tackle Complex Machine Learning Problems Using Python, Packt Publishing, Limited, 2018. \n",
    "# ProQuest Ebook Central, Available at: http://ebookcentral.proquest.com/lib/nottingham/detail.action?docID=5379696.\n",
    "\n",
    "# Outlier detection using the following methods:\n",
    "# 1. Percentile based outlier detection\n",
    "# 2. MAD (median absolute deviation) based outlier detection\n",
    "# 3. Standard deviation based outlier detection\n",
    "\n",
    "\"\"\" \n",
    "    Get all the data points that lie under the percentile range from 2.5 to 97.5\n",
    "\"\"\"\n",
    "def percentile_based_outlier(data, threshold=95):\n",
    "    diff = (100 - threshold) / 2.0\n",
    "    minval, maxval = np.percentile(data, [diff, 100 - diff])\n",
    "    return (data < minval) | (data > maxval)\n",
    "\n",
    "\"\"\"\n",
    "    Get all the data points that lie under a threshold of 3.5 using modified Z-score (based on the median absolute deviation)\n",
    "\"\"\"\n",
    "def mad_based_outlier(points, threshold=3.5):\n",
    "    points = np.array(points)\n",
    "    if len(points.shape) == 1:\n",
    "        points = points[:, None]\n",
    "    median_y = np.median(points)\n",
    "    median_absolute_deviation_y = np.median([np.abs(y - median_y) for y in points])\n",
    "    # Small constant added to avoid division by zero\n",
    "    modified_z_scores = [0.6745 * (y - median_y) / (median_absolute_deviation_y + 1e-6) for y in points]\n",
    "\n",
    "    return np.abs(modified_z_scores) > threshold\n",
    "\n",
    "\"\"\"\n",
    "    Get all the data points that lie under a threshold of 3 using standard deviation\n",
    "\"\"\"\n",
    "def std_div(data, threshold=3):\n",
    "    std = data.std()\n",
    "    mean = data.mean()\n",
    "    isOutlier = []\n",
    "    for val in data:\n",
    "        if abs(val - mean)/std > threshold:\n",
    "            isOutlier.append(True)\n",
    "        else:\n",
    "            isOutlier.append(False)\n",
    "    return isOutlier\n",
    "\n",
    "\"\"\"\n",
    "    Perform an outlier voting system to determine if a data point is an outlier. \n",
    "    If two of the three methods agree that a data point is an outlier, then it is removed.\n",
    "\"\"\"\n",
    "def outlierVote(data):\n",
    "    x = percentile_based_outlier(data)\n",
    "    y = mad_based_outlier(data)\n",
    "    z = std_div(data)\n",
    "    temp = list(zip(x, y, z))\n",
    "    final = []\n",
    "    for i in range(len(temp)):\n",
    "        if temp[i].count(False) >= 2:\n",
    "            final.append(False)\n",
    "        else:\n",
    "            final.append(True)\n",
    "    return final\n",
    "\n",
    "def removeOutliers(data):\n",
    "    # Remove outliers from the dataframe\n",
    "    for column in data.columns:\n",
    "        outliers = outlierVote(all_df[column])\n",
    "        # Calculate Non-Outlier Maximum using the outliers list\n",
    "        non_outlier_max = all_df.loc[~np.array(outliers), column].max()\n",
    "        # Replace outliers with the maximum non-outlier value\n",
    "        data.loc[outliers, column] = non_outlier_max\n",
    "\n",
    "# Remove outliers, assign modified features to X and drop the outcome columns\n",
    "removeOutliers(all_df)\n",
    "X = all_df.drop(['pCR (outcome)', 'RelapseFreeSurvival (outcome)'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalisation/Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardise features by removing the mean and scaling to unit variance.\n",
    "scaler = StandardScaler()\n",
    "Xs = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Feature 0 (0.595337)\n",
      "2. Feature 7 (0.128023)\n",
      "3. Feature 4 (0.067312)\n",
      "4. Feature 6 (0.054164)\n",
      "5. Feature 1 (0.051488)\n",
      "6. Feature 2 (0.045331)\n",
      "7. Feature 5 (0.029399)\n",
      "8. Feature 3 (0.028947)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalise the features to use zero mean normalisation\n",
    "scaler = StandardScaler()\n",
    "Xs = scaler.fit_transform(X)\n",
    "\n",
    "mandatory_features = ['ER', 'HER2', 'Gene']\n",
    "mandatory_features_indices = [1,3,10]\n",
    "\n",
    "x_required = Xs[:, mandatory_features_indices]\n",
    "mri_indices = list(range(11, Xs.shape[1]))\n",
    "\n",
    "X_non_required = np.delete(Xs, mri_indices, axis=1)\n",
    "X_non_required = np.delete(X_non_required, mandatory_features_indices, axis=1)\n",
    "\n",
    "\n",
    "# Apply LDA to all features except required ones\n",
    "lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "Xs_lda = lda.fit_transform(mri, clf_y)\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=1000, random_state=0, n_jobs=-1)\n",
    "rnd_clf.fit(X_non_required, clf_y)\n",
    "importances = rnd_clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for i in range(X_non_required.shape[1]):\n",
    "    print(\"%d. Feature %d (%f)\" % (i + 1, indices[i], importances[indices[i]]))\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "plt.bar(range(X_non_required.shape[1]), importances[indices], align='center')\n",
    "plt.xticks(range(X_non_required.shape[1]), indices)\n",
    "plt.xlim([-1, X_non_required.shape[1]])\n",
    "plt.show()\n",
    "\n",
    "X_non_required_selected = X_non_required[:, indices[:4]]\n",
    "\n",
    "# Combine required features with LDA transformed features\n",
    "Xs = np.hstack((x_required, Xs_lda, X_non_required_selected))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.845 (0.052)\n",
      "Best Model: SVC(C=10, gamma=0.01, random_state=2)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93       316\n",
      "           1       0.82      0.63      0.71        84\n",
      "\n",
      "    accuracy                           0.89       400\n",
      "   macro avg       0.86      0.80      0.82       400\n",
      "weighted avg       0.89      0.89      0.89       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from numpy._core.fromnumeric import mean\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from numpy import std\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# this nested cross-validation is used to tune the hyperparameters of the model\n",
    "# the code was adapted from: \n",
    "# Brownlee, J. (2018). Nested Cross-Validation for Machine Learning with Python. [online] Machine Learning Mastery.\n",
    "# Available at: https://machinelearningmastery.com/nested-cross-validation-for-machine-learning-with-python/ [Accessed 5 Dec. 2024]\n",
    "\n",
    "# configure the cross-validation procedure for the inner loop\n",
    "cv_inner = KFold(n_splits=5, shuffle=True, random_state=2)\n",
    "\n",
    "# define the classifier\n",
    "classifier = SVC(random_state=2)\n",
    "\n",
    "# define search space of hyperparameters\n",
    "space = dict()\n",
    "space['C'] = [0.1, 1, 10]\n",
    "space['gamma'] = [0.01, 0.1]\n",
    "space['kernel'] = [\"rbf\", \"linear\", \"poly\"]\n",
    "\n",
    "# define GridSearch to search for the best hyperparameters\n",
    "search = GridSearchCV(classifier, space, scoring='accuracy', n_jobs=1, cv=cv_inner, refit=True)\n",
    "\n",
    "# configure the cross-validation procedure for the outer loop\n",
    "cv_outer = KFold(n_splits=5, shuffle=True, random_state=2)\n",
    "\n",
    "# execute the nested cross-validation\n",
    "scores = cross_val_score(search, Xs, clf_y, scoring='accuracy', cv=cv_outer, n_jobs=-1)\n",
    "\n",
    "# fit the search on the whole dataset to get the best model\n",
    "search.fit(Xs, clf_y)\n",
    "model = search.best_estimator_\n",
    "\n",
    "# report performance and best model configuration\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "print('Best Model:', model)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Print f1-score, precision, recall and support\n",
    "y_pred = model.predict(Xs)\n",
    "print(classification_report(clf_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.838 (0.025)\n",
      "Best Model: RandomForestClassifier(max_features=4, n_estimators=500, random_state=1)\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest Model:\u001b[39m\u001b[38;5;124m'\u001b[39m, best_model)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Print f1-score, precision, recall and support\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(clf_y, y_pred))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/MLE/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:904\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    884\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[1;32m    886\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 904\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/MLE/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:944\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    923\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;124;03m    Predict class probabilities for X.\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;124;03m        classes corresponds to that in the attribute :term:`classes_`.\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 944\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    945\u001b[0m     \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m    946\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/MLE/lib/python3.10/site-packages/sklearn/utils/validation.py:1661\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[1;32m   1660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[0;32m-> 1661\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "from numpy import mean, std\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# configure the cross-validation procedure\n",
    "cv_inner = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# define the model\n",
    "model = RandomForestClassifier(random_state=1)\n",
    "# define search space\n",
    "space = dict()\n",
    "space['n_estimators'] = [10, 100, 500]\n",
    "space['max_features'] = [2, 4, 6]\n",
    "# define search\n",
    "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=1, cv=cv_inner, refit=True)\n",
    "# configure the cross-validation procedure\n",
    "cv_outer = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# execute the nested cross-validation\n",
    "scores = cross_val_score(search, Xs, clf_y, scoring='accuracy', cv=cv_outer, n_jobs=-1)\n",
    "# fit the search on the whole dataset to get the best model\n",
    "search.fit(Xs, clf_y)\n",
    "best_model = search.best_estimator_\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "print('Best Model:', best_model)\n",
    "\n",
    "# Print f1-score, precision, recall and support\n",
    "y_pred = model.predict(Xs)\n",
    "print(classification_report(clf_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.792 (0.024)\n",
      "Best Model: LogisticRegression(C=10, random_state=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# configure the cross-validation procedure\n",
    "cv_inner = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# define the model\n",
    "model = LogisticRegression(random_state=1)\n",
    "# define search space\n",
    "space = dict()\n",
    "space['C'] = [0.1, 1, 10, 100]\n",
    "# define search\n",
    "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=1, cv=cv_inner, refit=True)\n",
    "# configure the cross-validation procedure\n",
    "cv_outer = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# execute the nested cross-validation\n",
    "scores = cross_val_score(search, Xs, clf_y, scoring='accuracy', cv=cv_outer, n_jobs=-1)\n",
    "# fit the search on the whole dataset to get the best model\n",
    "search.fit(Xs, clf_y)\n",
    "best_model = search.best_estimator_\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "print('Best Model:', best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/MLE/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/MLE/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/MLE/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/MLE/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy for PCR (cross-validated): 0.6094590053763441 Â± 0.021335278216603762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/MLE/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_pCR = MLPClassifier(random_state=1, max_iter=1000)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "cv_scores_pCR = cross_val_score(mlp_pCR, Xs, clf_y, cv=kfold, scoring='balanced_accuracy')\n",
    "print(f'Balanced Accuracy for PCR (cross-validated): {cv_scores_pCR.mean()} Â± {cv_scores_pCR.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/MLE/lib/python3.10/site-packages/numpy/ma/core.py:2881: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n",
      "/opt/anaconda3/envs/MLE/lib/python3.10/site-packages/numpy/ma/core.py:2881: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.795 (0.017)\n",
      "Best Model: KNeighborsClassifier(metric='euclidean')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# configure the cross-validation procedure\n",
    "cv_inner = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# define the model\n",
    "model = KNeighborsClassifier()\n",
    "# define search space\n",
    "space = dict()\n",
    "space['n_neighbors'] = [1, 5, 10, 15, 20]\n",
    "space['metric'] = ['euclidean', 'manhattan', 'minkowski']\n",
    "# define search\n",
    "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=1, cv=cv_inner, refit=True)\n",
    "# configure the cross-validation procedure\n",
    "cv_outer = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# execute the nested cross-validation\n",
    "scores = cross_val_score(search, Xs, clf_y, scoring='accuracy', cv=cv_outer, n_jobs=-1)\n",
    "# fit the search on the whole dataset to get the best model\n",
    "search.fit(Xs, clf_y)\n",
    "best_model = search.best_estimator_\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "print('Best Model:', best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "#joblib.dump({\"model\": model, \"scaler\": scaler, \"lda\": lda}, 'pcr_classification_model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
