{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e864c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pCR (outcome)</th>\n",
       "      <th>RelapseFreeSurvival (outcome)</th>\n",
       "      <th>Age</th>\n",
       "      <th>ER</th>\n",
       "      <th>PgR</th>\n",
       "      <th>HER2</th>\n",
       "      <th>TrippleNegative</th>\n",
       "      <th>ChemoGrade</th>\n",
       "      <th>Proliferation</th>\n",
       "      <th>HistologyType</th>\n",
       "      <th>...</th>\n",
       "      <th>original_glszm_SmallAreaHighGrayLevelEmphasis</th>\n",
       "      <th>original_glszm_SmallAreaLowGrayLevelEmphasis</th>\n",
       "      <th>original_glszm_ZoneEntropy</th>\n",
       "      <th>original_glszm_ZonePercentage</th>\n",
       "      <th>original_glszm_ZoneVariance</th>\n",
       "      <th>original_ngtdm_Busyness</th>\n",
       "      <th>original_ngtdm_Coarseness</th>\n",
       "      <th>original_ngtdm_Complexity</th>\n",
       "      <th>original_ngtdm_Contrast</th>\n",
       "      <th>original_ngtdm_Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>144.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517172</td>\n",
       "      <td>0.375126</td>\n",
       "      <td>3.325332</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>3880771.500</td>\n",
       "      <td>473.464852</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.182615</td>\n",
       "      <td>0.030508</td>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444391</td>\n",
       "      <td>0.444391</td>\n",
       "      <td>3.032144</td>\n",
       "      <td>0.005612</td>\n",
       "      <td>2372009.744</td>\n",
       "      <td>59.459710</td>\n",
       "      <td>0.004383</td>\n",
       "      <td>0.032012</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.003685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>135.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534549</td>\n",
       "      <td>0.534549</td>\n",
       "      <td>2.485848</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>1540027.421</td>\n",
       "      <td>33.935384</td>\n",
       "      <td>0.007584</td>\n",
       "      <td>0.024062</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.006447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506185</td>\n",
       "      <td>0.506185</td>\n",
       "      <td>2.606255</td>\n",
       "      <td>0.003755</td>\n",
       "      <td>6936740.794</td>\n",
       "      <td>46.859265</td>\n",
       "      <td>0.005424</td>\n",
       "      <td>0.013707</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.004543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.462282</td>\n",
       "      <td>0.462282</td>\n",
       "      <td>2.809279</td>\n",
       "      <td>0.006521</td>\n",
       "      <td>1265399.054</td>\n",
       "      <td>39.621023</td>\n",
       "      <td>0.006585</td>\n",
       "      <td>0.034148</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.005626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pCR (outcome)  RelapseFreeSurvival (outcome)   Age  ER  PgR  HER2  \\\n",
       "0              1                          144.0  41.0   0    0     0   \n",
       "1              0                          142.0  39.0   1    1     0   \n",
       "2              1                          135.0  31.0   0    0     0   \n",
       "3              0                           12.0  35.0   0    0     0   \n",
       "4              0                          109.0  61.0   1    0     0   \n",
       "\n",
       "   TrippleNegative  ChemoGrade  Proliferation  HistologyType  ...  \\\n",
       "0                1           3              3              1  ...   \n",
       "1                0           3              3              1  ...   \n",
       "2                1           2              1              1  ...   \n",
       "3                1           3              3              1  ...   \n",
       "4                0           2              1              1  ...   \n",
       "\n",
       "   original_glszm_SmallAreaHighGrayLevelEmphasis  \\\n",
       "0                                       0.517172   \n",
       "1                                       0.444391   \n",
       "2                                       0.534549   \n",
       "3                                       0.506185   \n",
       "4                                       0.462282   \n",
       "\n",
       "   original_glszm_SmallAreaLowGrayLevelEmphasis  original_glszm_ZoneEntropy  \\\n",
       "0                                      0.375126                    3.325332   \n",
       "1                                      0.444391                    3.032144   \n",
       "2                                      0.534549                    2.485848   \n",
       "3                                      0.506185                    2.606255   \n",
       "4                                      0.462282                    2.809279   \n",
       "\n",
       "   original_glszm_ZonePercentage  original_glszm_ZoneVariance  \\\n",
       "0                       0.002314                  3880771.500   \n",
       "1                       0.005612                  2372009.744   \n",
       "2                       0.006752                  1540027.421   \n",
       "3                       0.003755                  6936740.794   \n",
       "4                       0.006521                  1265399.054   \n",
       "\n",
       "   original_ngtdm_Busyness  original_ngtdm_Coarseness  \\\n",
       "0               473.464852                   0.000768   \n",
       "1                59.459710                   0.004383   \n",
       "2                33.935384                   0.007584   \n",
       "3                46.859265                   0.005424   \n",
       "4                39.621023                   0.006585   \n",
       "\n",
       "   original_ngtdm_Complexity  original_ngtdm_Contrast  original_ngtdm_Strength  \n",
       "0                   0.182615                 0.030508                 0.000758  \n",
       "1                   0.032012                 0.001006                 0.003685  \n",
       "2                   0.024062                 0.000529                 0.006447  \n",
       "3                   0.013707                 0.000178                 0.004543  \n",
       "4                   0.034148                 0.001083                 0.005626  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "all_df = pd.read_csv('TrainDataset2024.csv', index_col=False)\n",
    "all_df.drop('ID', axis=1, inplace=True)\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efab16a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\", missing_values=999)\n",
    "all_df[:] = imputer.fit_transform(all_df)\n",
    "\n",
    "# classification target\n",
    "clf_y = all_df['pCR (outcome)']\n",
    "# regression target\n",
    "rgr_y = all_df['RelapseFreeSurvival (outcome)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "069f12b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile_based_outlier(data, threshold=95):\n",
    "    diff = (100 - threshold) / 2.0\n",
    "    minval, maxval = np.percentile(data, [diff, 100 - diff])\n",
    "    return (data < minval) | (data > maxval)\n",
    "\n",
    "def mad_based_outlier(points, threshold=3.5):\n",
    "    points = np.array(points)\n",
    "    if len(points.shape) == 1:\n",
    "        points = points[:, None]\n",
    "    median_y = np.median(points)\n",
    "    median_absolute_deviation_y = np.median([np.abs(y - median_y) for y in points])\n",
    "    # Small constant added to avoid division by zero\n",
    "    modified_z_scores = [0.6745 * (y - median_y) / (median_absolute_deviation_y + 1e-6) for y in points]\n",
    "\n",
    "    return np.abs(modified_z_scores) > threshold\n",
    "\n",
    "def std_div(data, threshold=3):\n",
    "    std = data.std()\n",
    "    mean = data.mean()\n",
    "    isOutlier = []\n",
    "    for val in data:\n",
    "        if abs(val - mean)/std > threshold:\n",
    "            isOutlier.append(True)\n",
    "        else:\n",
    "            isOutlier.append(False)\n",
    "    return isOutlier\n",
    "\n",
    "def outlierVote(data):\n",
    "    x = percentile_based_outlier(data)\n",
    "    y = mad_based_outlier(data)\n",
    "    z = std_div(data)\n",
    "    temp = list(zip(x, y, z))\n",
    "    final = []\n",
    "    for i in range(len(temp)):\n",
    "        if temp[i].count(False) >= 2:\n",
    "            final.append(False)\n",
    "        else:\n",
    "            final.append(True)\n",
    "    return final\n",
    "\n",
    "def plotOutliers(x):\n",
    "    fig, axes = plt.subplots(nrows=4)\n",
    "    for ax, func in zip(axes, [percentile_based_outlier, mad_based_outlier, std_div, outlierVote]):\n",
    "        sns.distplot(x, ax=ax, rug=True, hist=False)\n",
    "        outliers = func(x)\n",
    "        ax.plot(outliers, np.zeros_like(outliers), 'ro', clip_on=False)\n",
    "\n",
    "    kwargs = dict(y=0.95, x=0.05, ha='left', va='top', size=20)\n",
    "    axes[0].set_title('Percentile-based Outliers', **kwargs)\n",
    "    axes[1].set_title('MAD-based Outliers', **kwargs)\n",
    "    axes[2].set_title('STD-based Outliers', **kwargs)\n",
    "    axes[3].set_title('Majority vote', **kwargs)\n",
    "    fig.suptitle('Comparing Outlier Tests with n={}'.format(len(x)), size=20)\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(20, 15)\n",
    "\n",
    "def removeOutliers(data):\n",
    "    # Remove outliers from the dataframe\n",
    "    for column in data.columns:\n",
    "        outliers = outlierVote(all_df[column])\n",
    "        # Calculate Non-Outlier Maximum using the outliers list\n",
    "        non_outlier_max = all_df.loc[~np.array(outliers), column].max()\n",
    "        # Replace outliers with the maximum non-outlier value\n",
    "        data.loc[outliers, column] = non_outlier_max\n",
    "\n",
    "removeOutliers(all_df)\n",
    "# Verify the changes\n",
    "all_df.head()\n",
    "\n",
    "# Assign features to X\n",
    "X = all_df.drop(['pCR (outcome)', 'RelapseFreeSurvival (outcome)'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e7cbb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Feature 3 (0.805559)\n",
      "2. Feature 2 (0.105200)\n",
      "3. Feature 1 (0.054946)\n",
      "4. Feature 0 (0.034295)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Normalise the features to use zero mean normalisation\n",
    "scaler = StandardScaler()\n",
    "Xs = scaler.fit_transform(X)\n",
    "\n",
    "# Dimensionality Reduction using PCA to reduce features to 2 components\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# USING PCA for all\n",
    "#pca.fit(Xs)\n",
    "#Xs = pca.transform(Xs)\n",
    "\n",
    "# USING PCA for only the MRI data\n",
    "#Xs_pca = pca.fit_transform(Xs[:, 11:])\n",
    "#Xs = np.hstack((Xs[:, :11], Xs_pca))\n",
    "\n",
    "required_features = Xs[:, [1, 3, 10]]\n",
    "\n",
    "# Apply LDA to all except required features\n",
    "lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "Xs_lda = lda.fit_transform(np.delete(Xs, [1, 3, 10], axis=1), clf_y)\n",
    "\n",
    "# Combine required features with LDA transformed features\n",
    "Xs = np.hstack((required_features, Xs_lda))\n",
    "\n",
    "Xs_train, Xs_test, y_train, y_test = train_test_split(Xs, clf_y.values.ravel(), test_size=0.2,\n",
    "random_state=1, stratify=clf_y)\n",
    "\n",
    "#lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "#Xs_lda = lda.fit_transform(Xs[:, 11:], clf_y)\n",
    "#Xs = np.hstack((Xs[:, :11], Xs_lda))\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=1000, random_state=0, n_jobs=-1)\n",
    "rnd_clf.fit(Xs_train, y_train)\n",
    "importances = rnd_clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for i in range(Xs_train.shape[1]):\n",
    "    print(\"%d. Feature %d (%f)\" % (i + 1, indices[i], importances[indices[i]]))\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "plt.bar(range(Xs_train.shape[1]), importances[indices], align='center')\n",
    "plt.xticks(range(Xs_train.shape[1]), indices)\n",
    "plt.xlim([-1, Xs_train.shape[1]])\n",
    "plt.show()\n",
    "\n",
    "#Xs = Xs[:, indices[:8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a2e5146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean cross-validation accuracy: 0.88\n",
      "The classifier accuracy score is 0.90\n",
      "mean cross-validation accuracy: 0.82\n",
      "The classifier accuracy score is 0.81\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "scores = cross_val_score(log_reg, Xs_train, y_train, cv=kf)\n",
    "\n",
    "mean_score = np.mean(scores)\n",
    "\n",
    "print(\"mean cross-validation accuracy: {:03.2f}\".format(mean_score))\n",
    "log_reg.fit(Xs_train, y_train)\n",
    "classifier_score = log_reg.score(Xs_test, y_test)\n",
    "print('The classifier accuracy score is {:03.2f}'.format(classifier_score))\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=1000, random_state=0, n_jobs=-1)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "scores = cross_val_score(rnd_clf, Xs_train, y_train, cv=kf)\n",
    "\n",
    "mean_score = np.mean(scores)\n",
    "\n",
    "print(\"mean cross-validation accuracy: {:03.2f}\".format(mean_score))\n",
    "rnd_clf.fit(Xs_train, y_train)\n",
    "classifier_score = rnd_clf.score(Xs_test, y_test)\n",
    "print('The classifier accuracy score is {:03.2f}'.format(classifier_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "569c6367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average fold score and standard deviation: (80.75 +- 0.570)%\n",
      "Optimal Hyper Parameter from list:\n",
      "['linear', 1]\n",
      "The classifier accuracy score is 0.89\n",
      "Average fold score and standard deviation: (88.12 +- 1.801)%\n"
     ]
    }
   ],
   "source": [
    "# SVM for classification\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# K fold value\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "svm_clf = SVC(C=0.1, kernel=\"rbf\", degree=3, gamma='auto')\n",
    "svm_clf.fit(Xs, clf_y)\n",
    "scores = cross_val_score(svm_clf, Xs, clf_y, cv=kf)\n",
    "\n",
    "avg = (100 * np.mean(scores), 100 * np.std(scores)/np.sqrt(scores.shape[0]))\n",
    "print(\"Average fold score and standard deviation: (%.2f +- %.3f)%%\" %avg)\n",
    "\n",
    "kernel_list = ['rbf', 'poly', 'linear']\n",
    "C_values_list = [0.1, 1, 10, 20, 50, 100]\n",
    "\n",
    "hyper_parameter_score_list = []\n",
    "\n",
    "# K fold value\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "for kernel in kernel_list:\n",
    "    for c in C_values_list:\n",
    "        # avoid computational expensive poly and linear svm\n",
    "        if (kernel == \"poly\" or kernel == \"linear\") and c > 20: break\n",
    "        svm_clf = SVC(C=c, kernel=kernel, degree=3, gamma='auto')\n",
    "        scores = cross_validate(svm_clf, Xs_train, y_train, cv=kf, scoring=\"accuracy\")\n",
    "        mean_scores = np.mean(scores['test_score'])\n",
    "        hyper_parameter_score_list.append([kernel, c, mean_scores])\n",
    "\n",
    "optimal_hyper_parameter = max(hyper_parameter_score_list, key=lambda x: x[2])\n",
    "print(\"Optimal Hyper Parameter from list:\")\n",
    "print(optimal_hyper_parameter[:2])\n",
    "\n",
    "svm_clf = SVC(C=optimal_hyper_parameter[1], kernel=optimal_hyper_parameter[0], degree=3, gamma='auto')\n",
    "svm_clf.fit(Xs_train, y_train)\n",
    "scores = cross_val_score(svm_clf, Xs_train, y_train, cv=kf)\n",
    "classifier_score = svm_clf.score(Xs_test, y_test)\n",
    "print('The classifier accuracy score is {:03.2f}'.format(classifier_score))\n",
    "\n",
    "avg = (100 * np.mean(scores), 100 * np.std(scores)/np.sqrt(scores.shape[0]))\n",
    "print(\"Average fold score and standard deviation: (%.2f +- %.3f)%%\" %avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9721f9b",
   "metadata": {},
   "source": [
    "LDA performs well to increase accuracy. Need to check for any overfitting.\n",
    "LDA for MRI only also does good."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
