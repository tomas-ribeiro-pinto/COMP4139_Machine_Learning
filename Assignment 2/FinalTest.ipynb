{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlrd in /Users/stephen/Library/Caches/pypoetry/virtualenvs/labs-env-NHQiDXzZ-py3.12/lib/python3.12/site-packages (2.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Install xlrd package\n",
    "%pip install xlrd\n",
    "\n",
    "all_df = pd.read_excel('TestDatasetExample.xls', index_col=False)\n",
    "IDs = all_df['ID']\n",
    "all_df.drop('ID', axis=1, inplace=True)\n",
    "all_df.head()\n",
    "\n",
    "saved_model = joblib.load('pcr_classification_model.joblib')\n",
    "model = saved_model['model']\n",
    "scaler = saved_model['scaler']\n",
    "lda = saved_model['lda']\n",
    "selected_features_indices = saved_model['selected_features_indices']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Process testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dl/k40b_cq90vj9wb36fl6cz3_w0000gn/T/ipykernel_14473/515753628.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.  0.5 1. ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_df[:] = imputer.fit_transform(all_df)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Replace missing values with median of the column\n",
    "imputer = SimpleImputer(strategy=\"median\", missing_values=999)\n",
    "all_df[:] = imputer.fit_transform(all_df)\n",
    "\n",
    "# Standardize the data\n",
    "Xs = scaler.transform(all_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Feature Selection and Dimensionality Reduction training strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Select required features (ER, HER2 and Gene)\n",
    "non_mri_features = Xs[:, selected_features_indices]\n",
    "\n",
    "# Select MRI features\n",
    "mri_indices = list(range(11, Xs.shape[1]))\n",
    "mri = Xs[:, mri_indices]\n",
    "\n",
    "# Apply LDA to MRI features\n",
    "Xs_lda = lda.transform(Xs[:, 11:])\n",
    "\n",
    "# Combine required features with LDA transformed features\n",
    "Xs = np.hstack((non_mri_features, Xs_lda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(Xs)\n",
    "\n",
    "# Add the prediction to the dataframe\n",
    "all_df['pCR (outcome)'] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: RFS Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no missing Gene - skipping gene impute\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pickle\n",
    "\n",
    "# load gene clf feature names\n",
    "import json\n",
    "keep_feat_names = []\n",
    "with open('gene_clf_selected_features.json', 'rb') as f:\n",
    "  keep_feat_names = json.load(f)\n",
    "\n",
    "if 999 not in all_df['Gene'].values:\n",
    "  print(\"no missing Gene - skipping gene impute\")\n",
    "else:\n",
    "  # replace missing gene with classification result\n",
    "  # see train_gene_classifier.ipynb for more details\n",
    "  with open('log_reg_gene_classifier.pkl', 'rb') as f:\n",
    "    log_res_clf = pickle.load(f)\n",
    "\n",
    "    # rebuild prediction df\n",
    "    gene_impute_df = all_df.copy()\n",
    "\n",
    "    temp_X = gene_impute_df.drop(['pCR (outcome)'], axis=1)\n",
    "    y = gene_impute_df['Gene']\n",
    "\n",
    "    print(\"before impute:\") \n",
    "    print(gene_impute_df['Gene'].value_counts())\n",
    "\n",
    "    keep_df = gene_impute_df[keep_feat_names]\n",
    "    replace_index = keep_df[keep_df['Gene'] == 999].index\n",
    "\n",
    "    # get prediction on missing gene\n",
    "    target = gene_impute_df.loc[replace_index, keep_feat_names]\n",
    "    target.drop('Gene', axis=1, inplace=True)\n",
    "\n",
    "    print(\"target shape:\", target.shape)\n",
    "\n",
    "    pred = log_res_clf.predict(target)\n",
    "    gene_impute_df.loc[replace_index, 'Gene'] = pred\n",
    "\n",
    "    print(\"after impute:\") \n",
    "    print(gene_impute_df['Gene'].value_counts())\n",
    "\n",
    "    # assign back to all_df\n",
    "    all_df['Gene'] = gene_impute_df['Gene']\n",
    "\n",
    "\n",
    "  # Replace missing values with median of the column\n",
    "  imputer = SimpleImputer(strategy=\"median\", missing_values=999)\n",
    "  all_df[:] = imputer.fit_transform(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "Xs = scaler.fit_transform(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'ER', 'PgR', 'HER2', 'TrippleNegative', 'ChemoGrade',\n",
      "       'Proliferation', 'HistologyType', 'LNStatus', 'TumourStage', 'Gene',\n",
      "       'original_shape_Elongation', 'original_shape_Flatness'],\n",
      "      dtype='object')\n",
      "Index(['original_shape_LeastAxisLength', 'original_shape_MajorAxisLength',\n",
      "       'original_shape_Maximum2DDiameterColumn',\n",
      "       'original_shape_Maximum2DDiameterRow',\n",
      "       'original_shape_Maximum2DDiameterSlice',\n",
      "       'original_shape_Maximum3DDiameter', 'original_shape_MeshVolume',\n",
      "       'original_shape_MinorAxisLength', 'original_shape_Sphericity',\n",
      "       'original_shape_SurfaceArea',\n",
      "       ...\n",
      "       'original_glszm_SmallAreaLowGrayLevelEmphasis',\n",
      "       'original_glszm_ZoneEntropy', 'original_glszm_ZonePercentage',\n",
      "       'original_glszm_ZoneVariance', 'original_ngtdm_Busyness',\n",
      "       'original_ngtdm_Coarseness', 'original_ngtdm_Complexity',\n",
      "       'original_ngtdm_Contrast', 'original_ngtdm_Strength', 'pCR (outcome)'],\n",
      "      dtype='object', length=106)\n",
      "final shape:\n",
      "(3, 14)\n"
     ]
    }
   ],
   "source": [
    "### Feature Selection and Dimensionality Reduction strategy:\n",
    "#\n",
    "# 1. Keep all non mri columns\n",
    "# 2. Select the mri_pca_2MRI features and apply PCA\n",
    "# 3. Combine the two sets of features\n",
    "\n",
    "non_mri_indicies = list(range(13))\n",
    "print(all_df.columns[non_mri_indicies])\n",
    "\n",
    "# Select the MRI features\n",
    "mri_indices = list(range(13, Xs.shape[1]))\n",
    "print(all_df.columns[mri_indices])\n",
    "\n",
    "# Apply PCA to the MRI features\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=1)\n",
    "X_mri = Xs[:, mri_indices]\n",
    "X_mri_pca = pca.fit_transform(X_mri)\n",
    "\n",
    "# Combine the two sets of features\n",
    "non_mri_feats = Xs[:, non_mri_indicies]\n",
    "Xs = np.hstack([non_mri_feats, X_mri_pca])\n",
    "\n",
    "print(\"final shape:\")\n",
    "print(Xs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rfs_regression_model.pkl', 'rb') as f:\n",
    "  rfs_model = pickle.load(f)\n",
    "\n",
    "  # predict RFS\n",
    "  rfs_pred = rfs_model.predict(Xs)\n",
    "  \n",
    "  all_df['RelapseFreeSurvival (outcome)'] = rfs_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pCR (outcome)  RelapseFreeSurvival (outcome)\n",
      "0              0                      51.998804\n",
      "1              1                      53.630021\n",
      "2              0                      47.038868\n"
     ]
    }
   ],
   "source": [
    "print(all_df.loc[:, ['pCR (outcome)', 'RelapseFreeSurvival (outcome)']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save to results to csv\n",
    "\n",
    "pcr_coutcome = all_df['pCR (outcome)']\n",
    "rfs_coutcome = all_df['RelapseFreeSurvival (outcome)']\n",
    "\n",
    "clf_outcome = pd.DataFrame({'ID': IDs,'pCR (outcome)': pcr_coutcome,})\n",
    "\n",
    "reg_outcome = pd.DataFrame({'ID': IDs,'RelapseFreeSurvival (outcome)': rfs_coutcome,})\n",
    "\n",
    "clf_outcome.to_csv('results/classification_outcome.csv', index=False)\n",
    "reg_outcome.to_csv('results/regression_outcome.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labs-env-NHQiDXzZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
