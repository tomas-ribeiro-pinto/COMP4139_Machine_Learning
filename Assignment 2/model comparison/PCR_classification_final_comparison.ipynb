{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Install xlrd package\n",
    "%pip install xlrd\n",
    "\n",
    "all_df = pd.read_excel('../TrainDataset2024.xls', index_col=False)\n",
    "all_df.drop('ID', axis=1, inplace=True)\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Replace missing values with median of the column\n",
    "imputer = SimpleImputer(strategy=\"median\", missing_values=999)\n",
    "all_df[:] = imputer.fit_transform(all_df)\n",
    "\n",
    "# classification target\n",
    "clf_y = all_df['pCR (outcome)']\n",
    "# regression target\n",
    "rgr_y = all_df['RelapseFreeSurvival (outcome)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier removal approach by:\n",
    "# Thanaki, Jalaj. Machine Learning Solutions : Expert Techniques to Tackle Complex Machine Learning Problems Using Python, Packt Publishing, Limited, 2018. \n",
    "# ProQuest Ebook Central, Available at: http://ebookcentral.proquest.com/lib/nottingham/detail.action?docID=5379696.\n",
    "\n",
    "# Outlier detection using the following methods:\n",
    "# 1. Percentile based outlier detection\n",
    "# 2. MAD (median absolute deviation) based outlier detection\n",
    "# 3. Standard deviation based outlier detection\n",
    "\n",
    "\"\"\" \n",
    "    Get all the data points that lie under the percentile range from 2.5 to 97.5\n",
    "\"\"\"\n",
    "def percentile_based_outlier(data, threshold=95):\n",
    "    diff = (100 - threshold) / 2.0\n",
    "    minval, maxval = np.percentile(data, [diff, 100 - diff])\n",
    "    return (data < minval) | (data > maxval)\n",
    "\n",
    "\"\"\"\n",
    "    Get all the data points that lie under a threshold of 3.5 using modified Z-score (based on the median absolute deviation)\n",
    "\"\"\"\n",
    "def mad_based_outlier(points, threshold=3.5):\n",
    "    points = np.array(points)\n",
    "    if len(points.shape) == 1:\n",
    "        points = points[:, None]\n",
    "    median_y = np.median(points)\n",
    "    median_absolute_deviation_y = np.median([np.abs(y - median_y) for y in points])\n",
    "    # Small constant added to avoid division by zero\n",
    "    modified_z_scores = [0.6745 * (y - median_y) / (median_absolute_deviation_y + 1e-6) for y in points]\n",
    "\n",
    "    return np.abs(modified_z_scores) > threshold\n",
    "\n",
    "\"\"\"\n",
    "    Get all the data points that lie under a threshold of 3 using standard deviation\n",
    "\"\"\"\n",
    "def std_div(data, threshold=3):\n",
    "    std = data.std()\n",
    "    mean = data.mean()\n",
    "    isOutlier = []\n",
    "    for val in data:\n",
    "        if abs(val - mean)/std > threshold:\n",
    "            isOutlier.append(True)\n",
    "        else:\n",
    "            isOutlier.append(False)\n",
    "    return isOutlier\n",
    "\n",
    "\"\"\"\n",
    "    Perform an outlier voting system to determine if a data point is an outlier. \n",
    "    If two of the three methods agree that a data point is an outlier, then it is removed.\n",
    "\"\"\"\n",
    "def outlierVote(data):\n",
    "    x = percentile_based_outlier(data)\n",
    "    y = mad_based_outlier(data)\n",
    "    z = std_div(data)\n",
    "    temp = list(zip(x, y, z))\n",
    "    final = []\n",
    "    for i in range(len(temp)):\n",
    "        if temp[i].count(False) >= 2:\n",
    "            final.append(False)\n",
    "        else:\n",
    "            final.append(True)\n",
    "    return final\n",
    "\n",
    "def removeOutliers(data):\n",
    "    # Remove outliers from the dataframe\n",
    "    for column in data.columns:\n",
    "        outliers = outlierVote(all_df[column])\n",
    "        # Calculate Non-Outlier Maximum and minimum using the outliers list\n",
    "        non_outlier_max = all_df.loc[~np.array(outliers), column].max()\n",
    "        non_outlier_min = all_df.loc[~np.array(outliers), column].min()\n",
    "\n",
    "        # Replace outliers with the maximum or minimum non-outlier value\n",
    "        for i, outlier in enumerate(outliers):\n",
    "            if outlier:\n",
    "                data.loc[i, column] = non_outlier_max if data.loc[i, column] > non_outlier_max else non_outlier_min\n",
    "\n",
    "# Remove outliers, assign modified features to X and drop the outcome columns\n",
    "removeOutliers(all_df)\n",
    "X = all_df.drop(['pCR (outcome)', 'RelapseFreeSurvival (outcome)'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalisation/Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardise features by removing the mean and scaling to unit variance.\n",
    "scaler = StandardScaler()\n",
    "Xs = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection and Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "### Feature Selection and Dimensionality Reduction strategy:\n",
    "#\n",
    "# 1. Select the mandatory features ER, HER2 and Gene\n",
    "# 2. Select the MRI features and apply LDA to them\n",
    "# 3. Select the top 3 features of the remaining features using Random Forest\n",
    "\n",
    "# Select the mandatory features\n",
    "mandatory_features = ['ER', 'HER2', 'Gene']\n",
    "mandatory_features_indices = [1,3,10]\n",
    "features_required = Xs[:, mandatory_features_indices]\n",
    "\n",
    "### Dimensionality Reduction\n",
    "\n",
    "# Select the MRI features\n",
    "mri_indices = list(range(11, Xs.shape[1]))\n",
    "mri = Xs[:, mri_indices]\n",
    "\n",
    "# Apply LDA to MRI features\n",
    "lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "Xs_lda = lda.fit_transform(mri, clf_y)\n",
    "\n",
    "### Feature Selection\n",
    "\n",
    "# Remove the MRI features from the feature set\n",
    "non_mri_features = np.delete(Xs, mri_indices, axis=1)\n",
    "\n",
    "# Feature selection using Random Forest\n",
    "rnd_clf = RandomForestClassifier(n_estimators=1000, random_state=0, n_jobs=-1)\n",
    "rnd_clf.fit(non_mri_features, clf_y)\n",
    "\n",
    "# Get the feature importances\n",
    "importances = rnd_clf.feature_importances_\n",
    "# Get the indices of the features sorted by importance\n",
    "selected_indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.title('Feature Importances')\n",
    "plt.bar(range(non_mri_features.shape[1]), importances[selected_indices], align='center')\n",
    "plt.xticks(range(non_mri_features.shape[1]), selected_indices)\n",
    "plt.xlim([-1, non_mri_features.shape[1]])\n",
    "plt.show()\n",
    "\n",
    "# Select the top 3 features that are not mandatory features [ER, HER2, Gene]\n",
    "top_features_indices = [i for i in selected_indices if i not in mandatory_features_indices][:3]\n",
    "top_features = non_mri_features[:, top_features_indices]\n",
    "\n",
    "# Combine selected features and LDA transformed feature\n",
    "Xs = np.hstack((features_required, top_features, Xs_lda))\n",
    "\n",
    "selected_features_indices = sorted(mandatory_features_indices + [int(i) for i in top_features_indices])\n",
    "print('Selected Features:', selected_features_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, clf_y, test_size=0.2, random_state=42, stratify=clf_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy._core.fromnumeric import mean\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from numpy import std\n",
    "\n",
    "# this nested cross-validation is used to tune the hyperparameters of the model\n",
    "# the code was adapted from: \n",
    "#  \n",
    "\n",
    "# configure the cross-validation procedure for the inner loop\n",
    "cv_inner = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# define the classifier\n",
    "classifier = SVC(random_state=42)\n",
    "\n",
    "# define search space of hyperparameters\n",
    "space = dict()\n",
    "space['C'] = [0.1, 1, 10]\n",
    "space['gamma'] = [0.01, 0.1]\n",
    "space['kernel'] = [\"rbf\", \"linear\", \"poly\"]\n",
    "\n",
    "# define GridSearch to search for the best hyperparameters\n",
    "search = GridSearchCV(classifier, space, scoring='accuracy', n_jobs=1, cv=cv_inner, refit=True)\n",
    "\n",
    "# configure the cross-validation procedure for the outer loop\n",
    "cv_outer = KFold(n_splits=5, shuffle=True, random_state=2)\n",
    "\n",
    "# execute the nested cross-validation\n",
    "scores = cross_val_score(search, X_train, y_train, scoring='accuracy', cv=cv_outer, n_jobs=-1)\n",
    "\n",
    "# fit the search on the whole dataset to get the best model\n",
    "search.fit(X_train, y_train)\n",
    "model = search.best_estimator_\n",
    "\n",
    "# report performance and best model configuration\n",
    "print('Nested CV training Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "print('Best Model:', model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict using the test set\n",
    "y_pred = model.predict(X_test)\n",
    "# Print f1-score, precision, recall and support for prediction using the test set\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Test Accuracy: %.3f' % model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean, std\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# configure the cross-validation procedure\n",
    "cv_inner = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# define the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "# define search space\n",
    "space = dict()\n",
    "space['n_estimators'] = [10, 100, 500]\n",
    "space['max_features'] = [2, 4, 6]\n",
    "# define search\n",
    "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=1, cv=cv_inner, refit=True)\n",
    "# configure the cross-validation procedure\n",
    "cv_outer = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# execute the nested cross-validation\n",
    "scores = cross_val_score(search, X_train, y_train, scoring='accuracy', cv=cv_outer, n_jobs=-1)\n",
    "# fit the search on the whole dataset to get the best model\n",
    "search.fit(X_train, y_train)\n",
    "rf_model = search.best_estimator_\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "print('Best Model:', rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict using the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "# Print f1-score, precision, recall and support for prediction using the test set\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Test Accuracy: %.3f' % rf_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# configure the cross-validation procedure\n",
    "cv_inner = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# define the model\n",
    "model = LogisticRegression(random_state=42)\n",
    "# define search space\n",
    "space = dict()\n",
    "space['C'] = [0.1, 1, 10, 100]\n",
    "# define search\n",
    "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=1, cv=cv_inner, refit=True)\n",
    "# configure the cross-validation procedure\n",
    "cv_outer = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# execute the nested cross-validation\n",
    "scores = cross_val_score(search, X_train, y_train, scoring='accuracy', cv=cv_outer, n_jobs=-1)\n",
    "# fit the search on the whole dataset to get the best model\n",
    "search.fit(X_train, y_train)\n",
    "logistic_model = search.best_estimator_\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "print('Best Model:', logistic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict using the test set\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "# Print f1-score, precision, recall and support for prediction using the test set\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Test Accuracy: %.3f' % logistic_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# configure the cross-validation procedure\n",
    "cv_inner = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# define the model\n",
    "model = KNeighborsClassifier(weights='uniform')\n",
    "# define search space\n",
    "space = dict()\n",
    "space['n_neighbors'] = [1, 3, 5, 7, 10, 15, 20]\n",
    "space['metric'] = ['euclidean', 'manhattan', 'minkowski']\n",
    "# define search\n",
    "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=1, cv=cv_inner, refit=True)\n",
    "# configure the cross-validation procedure\n",
    "cv_outer = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# execute the nested cross-validation\n",
    "scores = cross_val_score(search, X_train, y_train, scoring='accuracy', cv=cv_outer, n_jobs=-1)\n",
    "# fit the search on the whole dataset to get the best model\n",
    "search.fit(X_train, y_train)\n",
    "knn_model = search.best_estimator_\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "print('Best Model:', knn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict using the test set\n",
    "y_pred = knn_model.predict(X_test)\n",
    "# Print f1-score, precision, recall and support for prediction using the test set\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Test Accuracy: %.3f' % knn_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stephen/Library/Caches/pypoetry/virtualenvs/labs-env-NHQiDXzZ-py3.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.863 (0.049)\n",
      "Best Model: MLPClassifier(activation='logistic', hidden_layer_sizes=(10,), max_iter=1000,\n",
      "              random_state=42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stephen/Library/Caches/pypoetry/virtualenvs/labs-env-NHQiDXzZ-py3.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# configure the cross-validation procedure\n",
    "cv_inner = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# define the model\n",
    "model = MLPClassifier(random_state=42, max_iter=1000)\n",
    "# define search space\n",
    "space = dict()\n",
    "space['activation'] = ['identity', 'logistic', 'tanh', 'relu']\n",
    "space['hidden_layer_sizes'] = [(10,), (50,), (100,), (200,)]\n",
    "space['solver'] = ['lbfgs', 'sgd', 'adam']\n",
    "# define search\n",
    "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=1, cv=cv_inner, refit=True)\n",
    "# configure the cross-validation procedure\n",
    "cv_outer = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# execute the nested cross-validation\n",
    "scores = cross_val_score(search, X_train, y_train, scoring='accuracy', cv=cv_outer, n_jobs=-1)\n",
    "# fit the search on the whole dataset to get the best model\n",
    "search.fit(X_train, y_train)\n",
    "mlp_model = search.best_estimator_\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "print('Best Model:', mlp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict using the test set\n",
    "y_pred = mlp_model.predict(X_test)\n",
    "# Print f1-score, precision, recall and support for prediction using the test set\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Test Accuracy: %.3f' % mlp_model.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labs-env-NHQiDXzZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
